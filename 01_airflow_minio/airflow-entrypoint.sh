#!/bin/bash
set -e

echo "‚úÖ Script airflow-entrypoint.sh ex√©cut√©"

connect_logs() {
  echo "üîó Cr√©ation de la connexion Airflow pour les logs S3 (MinIO)"

  if airflow connections get ${AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID} > /dev/null 2>&1; then
    echo "‚ÑπÔ∏è La connexion '${AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID}' existe d√©j√†, aucune action n√©cessaire."
  else
    echo "üÜï Cr√©ation de la connexion '${AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID}'"
    echo "üõ† airflow connections add ${AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID} --conn-type aws ..."
    airflow connections add ${AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID} \
      --conn-type 'aws' \
      --conn-extra "{
        \"aws_access_key_id\": \"${AWS_ACCESS_KEY_ID}\",
        \"aws_secret_access_key\": \"${AWS_SECRET_ACCESS_KEY}\",
        \"region_name\": \"us-east-1\",
        \"endpoint_url\": \"http://${DOCKER_MINIO_HOSTNAME}:${DOCKER_MINIO_PORT}\"
      }"
  fi
}

case "$1" in
  init)
    echo "üöÄ Initialisation de la base Airflow"
    airflow db migrate
    connect_logs
    ;;

  scheduler)
    echo "‚úÖ Lancement du scheduler d'Airflow"
    exec airflow "$@"
    ;;

  api-server)
    echo "‚úÖ Lancement de l'API Server d'Airflow"
    exec airflow "$@"
    ;;

  triggerer)
    echo "‚úÖ Lancement du triggerer d'Airflow"
    exec airflow "$@"
    ;;

  dag-processor)
    echo "‚úÖ Lancement du Dag Processor d'Airflow"
    exec airflow "$@"
    ;;

  celery-worker)
    echo "‚úÖ Lancement du worker Celery"
    exec airflow celery worker
    ;;

  *)
    echo "üîÅ Commande personnalis√©e : $@"
    exec "$@"
    ;;
esac
